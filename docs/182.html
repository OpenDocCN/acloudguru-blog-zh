<html>
<head>
<title>How does language, memory and package size affect cold starts of AWS Lambda? | A Cloud Guru</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>语言、内存、封装尺寸如何影响AWS Lambda的冷启动？|云专家</h1>
<blockquote>原文：<a href="https://acloudguru.com/blog/engineering/does-coding-language-memory-or-package-size-affect-cold-starts-of-aws-lambda#0001-01-01">https://acloudguru.com/blog/engineering/does-coding-language-memory-or-package-size-affect-cold-starts-of-aws-lambda#0001-01-01</a></blockquote><div><div class="elementor-widget-container"><p id="e40b">在最近的一篇博客中，我们研究了AWS Lambda本地支持的语言的运行时之间的性能差异。由于该实验对“热”功能的运行时间差异特别感兴趣，因此“冷启动”时间被有意省略。</p><blockquote class="wp-block-quote" id="af5c"><p>当AWS Lambda函数在长时间不使用后被调用时，会发生冷启动，从而导致调用延迟增加。</p></blockquote><p id="ed37">由于AWS Lambda 的<a href="https://acloudguru.com/blog/engineering/how-long-does-aws-lambda-keep-your-idle-functions-around-before-a-cold-start">冷启动时间是一个重要的性能考虑因素，让我们仔细看看一些实验，这些实验旨在隔离可能影响首次函数调用的变量。</a></p><h4 id="480c">测试方法</h4><p id="59c5">根据我在生产环境中运行Lambda函数的经验，冷启动通常发生在AWS Lambda函数空闲超过五分钟的时候。最近，我的一些功能直到空闲30分钟后才经历冷启动。即使您保持您的功能温暖，当主机虚拟机被回收时，大约每4小时就会发生一次冷启动—只需通过IO管道检查一下<a href="https://www.iopipe.com/2016/09/understanding-aws-lambda-coldstarts/" target="_blank" rel="noreferrer noopener">指标。</a></p><p id="19dd">出于测试目的，我需要一种可靠的方法来持续确保AWS Lambda函数的冷启动。创建冷启动的唯一可靠方法是在调用之前部署一个新版本的函数。</p><p id="224b">为了实验，我创建了45种AWS Lambda函数。使用下面的<a href="https://serverless.com/" target="_blank" rel="noreferrer noopener">无服务器</a>框架设置，很容易用不同的内存大小创建相同功能的变体。</p><p>我递归地部署了所有45个函数，并使用下面的简单脚本以编程方式调用它们中的每一个。</p>  <p id="b877">部署和调用循环大约需要三分钟。为了收集大量有意义的数据点，我进行了超过24小时的实验。</p><h4 id="5408">我最初的假设</h4><p id="fc23">我假设CPU资源的数量与分配给AWS Lambda函数的内存数量成正比。</p><ol><li>C#和Java会有更长的冷启动时间</li><li>内存大小线性影响冷启动时间</li><li>代码大小线性影响冷启动时间</li></ol><p id="caae">现在是时候看看实验是否支持我的假设了。</p><h4 id="053c">实验# 1——运行时间和内存的冷启动时间</h4><p id="fe95">为了评估内存对冷启动的影响，我创建了20个具有5个变量的函数——为每个语言运行时使用不同的内存大小。支持的语言有C#、Java、Node.js和Python。</p><div class="wp-block-image"><figure class="aligncenter size-large"><img loading="lazy" src="../Images/849a160f0414774c0061cb6de43d09c3.png" alt="" class="wp-image-42787" data-original-src="https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/1_uGcu7K7CWAysAz-symh2ow.png"/><figcaption>I created 5 variants of the same hello world function (using different memory sizes) for each language runtime<br/></figcaption></figure></div><p>在进行了24小时多一点的实验后，我收集了以下数据——以下是结果:</p><p id="d6c7"><strong>观察:C#和Java的冷启动时间要高得多</strong></p><p id="9494">最明显的趋势是，静态类型语言(C#和Java)的冷启动时间<strong>比</strong>高100多倍。这显然支持了我们的假设，尽管支持的程度比我原先预期的要大得多。</p><div class="wp-block-image"><figure class="aligncenter size-large"><img loading="lazy" src="../Images/e226e0ba9cacc9d2ae396d7e2edef294.png" alt="" class="wp-image-42788" data-original-src="https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/1_xqp9vLyYhDGpgMrDLNi3JQ.png"/><figcaption>Feel free play around with the interactive plot.ly chart <a href="https://web.archive.org/web/20190405210043/https://plot.ly/~theburningmonk/2/csharp-java-python-nodejs6/" rel="noreferrer noopener" target="_blank">here</a></figcaption></figure></div><p id="23f1"><strong>观察:Python的冷启动时间低得离谱</strong></p><p id="920d">我对Python运行时的冷启动体验如此之少感到惊喜。好吧，有一些异常数据点严重影响了一些99%和标准偏差，但你不能否认在128MB函数的95%处有0.41毫秒的冷启动时间。</p><p id="a944"><strong>观察:内存大小线性改善冷启动时间</strong></p><p id="0f76">分配给函数的内存越多，冷启动时间就越短，标准偏差就越小。这在C#和Java运行时中最为明显，因为基线(128MB)的冷启动时间对两者都非常重要。</p><p id="c7c5">到目前为止，第一次实验的数据支持了最初的假设。</p><h4 id="435a">实验# 2——按代码大小和内存划分的冷启动时间</h4><p id="8a4a">为了评估存储器和封装大小对冷启动的影响，我用不同的代码和存储器大小创建了25个函数。Node.js是这个实验的常量语言。</p><figure class="wp-block-image size-large"><img loading="lazy" src="../Images/36f191745ca104f0002a797da5e59836.png" alt="" class="wp-image-42781" data-original-src="https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/1_3kzYARUcZBQfIopsaUkZ_w.png"/></figure><p>以下是这次实验的结果:</p><figure class="wp-block-image size-large"><img loading="lazy" src="../Images/3d8827f6af99df6b75d24439615108f7.png" alt="" class="wp-image-42785" data-original-src="https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/1_Kng7sL4FVWBqfnjSidwqWQ.png"/></figure><figure class="wp-block-image size-large"><img loading="lazy" src="../Images/db8f62e18fd5221998348fff005689bc.png" alt="" class="wp-image-42784" data-original-src="https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/1_ESmdGFW2K6XxD9QGW3IawA.png"/></figure><p id="786f"><strong>观察:内存大小线性改善冷启动时间</strong></p><p id="4cba">与第一个实验一样，存储器大小以大致线性的方式改善了冷启动时间和标准偏差。</p><p id="62e3"><strong>观察#2:代码大小改善了冷启动时间</strong></p><p id="9247">有趣的是，部署包<em>的大小不会</em>增加冷启动时间。我会假设更大的包会相当于更多的时间来下载&amp;解压。相反，更大的部署包似乎对减少整体冷启动时间有积极的影响。</p><p id="24ea">为了看看行为是否一致，我希望其他人使用不同的语言运行时来重复这个实验。用于这些实验的源代码可以在<a href="https://github.com/theburningmonk/lambda-coldstart-comparison" target="_blank" rel="noreferrer noopener">这里</a>找到，包括用于计算统计数据和生成<a href="https://plot.ly/" target="_blank" rel="noreferrer noopener">图的脚本。</a></p><p><a href="https://github.com/theburningmonk/lambda-coldstart-comparison" target="_blank" rel="noreferrer noopener"><strong>the burningmonk/Lambda-cold start-comparison</strong>—<br/><em>Lambda-cold start-comparison——比较使用多种语言运行时的AWS Lambda函数的冷启动时间</em>—github.com</a></p><h4 id="59ab">结论</h4><p id="8c26">以下是我从这些实验中学到的一些东西:</p><ul><li>闲置大约5分钟后，功能不再被回收，这使得冷启动远没有以前那么糟糕</li><li>内存大小线性改善冷启动时间</li><li>C#和Java运行时的冷启动时间是Python的100倍左右，而且标准偏差也高得多</li><li>您应该考虑使用比Node.js/Python函数更高的内存分配来运行C#/Java Lambda函数</li><li>较大的部署包大小不会增加冷启动时间</li></ul><p id="4462"><strong>更新04/07/2017 </strong>:我贴了一个后续实验，想知道Lambda在回收闲置函数之前，会把它们保留多长时间。</p><p id="4462"/><hr class="wp-block-separator is-style-wide"/><h2 class="has-text-align-center" id="h-get-the-skills-you-need-for-a-better-career">获得更好职业所需的技能。</h2><p class="has-text-align-center">掌握现代技术技能，获得认证，提升您的职业生涯。无论您是新手还是经验丰富的专业人士，您都可以通过实践来学习，并在ACG的帮助下推进您的云计算职业生涯。</p><hr class="wp-block-separator is-style-wide"/></div></div>    
</body>
</html>
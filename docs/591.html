<html>
<head>
<title>Kinesis Data Streams: Auto Scaling with AWS Lambda | A Cloud Guru</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Kinesis数据流:使用AWS Lambda自动扩展|云专家</h1>
<blockquote>原文：<a href="https://acloudguru.com/blog/engineering/auto-scaling-kinesis-streams-with-aws-lambda#0001-01-01">https://acloudguru.com/blog/engineering/auto-scaling-kinesis-streams-with-aws-lambda#0001-01-01</a></blockquote><div><div class="elementor-widget-container"><h4 id="h-a-recipe-for-creating-a-cost-effective-solution-for-auto-scaling-kinesis-streams-using-lambda-functions">使用Lambda函数创建自动缩放Kinesis流的经济高效的解决方案的方法</h4><p id="fc2d">在我的<a href="https://read.acloud.guru/aws-lambda-3-pro-tips-for-working-with-kinesis-streams-8f6182a03113" target="_blank" rel="noreferrer noopener">上一篇文章</a>中，我们讨论了有效使用<em>λ</em>和<em> Kinesis的3个有用技巧。</em>现在让我们来看看如何使用<em> Lambda </em>作为自动缩放Kinesis流的经济高效的解决方案。</p><p id="b592"><em> DynamoDB </em>和<em> Kinesis </em>的自动缩放是AWS最常被要求的两个功能——当我写这篇文章时，我确信AWS的人们正在努力实现它。在此之前，以下是您如何自己推出经济高效的解决方案。</p><figure class="wp-block-image size-large"><img loading="lazy" src="../Images/29f0afa178f69c4a4a2b98abf65192f3.png" alt="" class="wp-image-41782" data-original-src="https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/1_D8nPXAWzIr8jsUSnBSQlKQ.png"/></figure><p id="0c26">从高层次来看，我们希望:</p><ul><li>快速扩展<em> Kinesis </em>流以满足负载的增加</li><li>缩减未充分利用的<em> Kinesis </em>流以节省成本</li></ul><h2 id="605b">自动缩放Kinesis数据流</h2><p id="e2ad">反应时间对于扩大规模很重要。根据个人经验，我发现轮询<em> CloudWatch </em>指标是一个糟糕的解决方案。原因如下:</p><ul><li>云观察指标通常会落后一分钟以上</li><li>根据轮询频率，反应时间甚至更慢</li><li>高轮询频率对成本的影响很小</li></ul><blockquote class="wp-block-quote"><p>在决定实施我们自己的解决方案之前，我用AWS实验室的<a href="https://github.com/awslabs/amazon-kinesis-scaling-utils" target="_blank" rel="noreferrer noopener"> <em> Kinesis </em>缩放工具</a>进行了简单的实验。我发现它的扩展速度不够快，因为它使用了这种轮询方法，而且我在使用<a href="https://github.com/sebdah/dynamic-dynamodb" target="_blank" rel="noreferrer noopener"> dynamic-dynamodb </a>时也遇到过类似的问题。</p></blockquote><p id="f915">相反，考虑使用基于推送的方法，使用<em> CloudWatch警报</em>。虽然<em> CloudWatch Alarms </em>不能作为<em> Lambda </em>功能的触发器，但您可以使用<em> SNS </em>作为代理:</p><ol><li>添加一个<em> SNS </em>话题作为<em> CloudWatch报警</em>的通知目标</li><li>将<em> SNS </em>主题作为<a href="https://acloudguru.com/hands-on-labs/setting-up-lambda-functions-with-s3-event-triggers">触发器添加到<em>Lambda</em>T5】函数中，以放大触发警报的流</a></li></ol><h2 id="6faa">触发自动缩放的指标</h2><p id="5e1c">您可以使用多个<a href="http://docs.aws.amazon.com/streams/latest/dev/monitoring-with-cloudwatch.html" target="_blank" rel="noreferrer noopener">指标</a>来触发缩放操作。这里有几个需要考虑的指标。</p><p id="3d22"><code><strong>WriteProvisionedThroughputExceeded</strong></code>(流)</p><p id="3a31">最简单的方法是一旦你被限制住了就扩大规模。使用<a href="http://docs.aws.amazon.com/streams/latest/dev/monitoring-with-cloudwatch.html#kinesis-metrics-stream" target="_blank" rel="noreferrer noopener">流级别度量</a>，您只需为每个流设置一次警报，无需在每次缩放操作后调整阈值。然而，由于您正在重用同一个<em> CloudWatch </em>警报，您必须记得在扩大规模后将其状态设置为<em> OK </em>。</p><p id="f104"><code><strong>IncomingBytes</strong></code>和/或<code><strong>IncomingRecords</strong></code>(流)</p><p id="2d2f">您可以通过计算调配的吞吐量，然后将警报阈值设置为调配吞吐量的80%，来抢先进行扩展(在您实际受到服务限制之前)。</p><p id="b7d3">毕竟，这正是我们在扩展EC2集群时要做的，同样的原则也适用于此——当您可以提前扩展时，为什么要等到受负载影响时再扩展呢？但是，我们需要管理EC2自动扩展服务中包含的一些额外的复杂性:</p><ul><li>如果我们对<code>IncomingBytes</code>和<code>IncomingRecords</code>都发出警报，那么如果两者几乎同时触发，就有可能扩大规模(影响成本)。这可以缓解，但我们有责任确保一次只能发生一个扩展操作，并且在每个扩展操作之后都有一个冷却过程</li><li>在每次扩展活动之后，我们需要重新计算调配的吞吐量并更新警报阈值</li></ul><p id="abeb"><code><strong>WriteProvisionedThroughputExceeded</strong></code>(碎片)</p><p id="81b2"><code><strong>IncomingBytes</strong></code>和/或<code><strong>IncomingRecords</strong></code>(碎片)</p><p id="a039">有了<a href="http://docs.aws.amazon.com/streams/latest/dev/monitoring-with-cloudwatch.html#kinesis-metrics-shard" target="_blank" rel="noreferrer noopener">分片级别的指标</a>，你就可以知道分片ID(在<em> SNS </em>消息中)的好处，这样你就可以通过分割特定分片来更精确地向上扩展。缺点是你必须在每次缩放操作后添加或删除<em> CloudWatch </em>警报。</p><h2 id="8538">如何放大Kinesis流</h2><p id="c41a">要真正放大一个<em> Kinesis </em>流，你需要通过分割一个或多个现有碎片来增加活动碎片的数量。需要记住的一点是，一旦一个碎片被一分为二，它就不再是<code>Active</code>——但它仍然可以被访问长达7天(取决于您的<em>保留策略</em>设置)。</p><p id="6a0b">概括地说，你有两种选择:</p><ol><li>使用<a href="http://docs.aws.amazon.com/kinesis/latest/APIReference/API_UpdateShardCount.html" target="_blank" rel="noreferrer noopener"> UpdateShardCount </a>并让Kinesis找出如何做</li><li>选择一个或多个碎片，并使用<a href="http://docs.aws.amazon.com/kinesis/latest/APIReference/API_SplitShard.html" target="_blank" rel="noreferrer noopener"> SplitShard </a>自行分割</li></ol><p id="080d"><em>选项1 — UpdateShardCount — </em>要简单得多，但这种方法有一些沉重的负担:</p><ul><li>因为它目前只支持<code>UNIFORM_SCALING</code>，这意味着这个动作会导致许多临时碎片被创建，除非你每次都加倍。</li><li>在大规模情况下，加倍可能非常昂贵，而且根据负载模式可能没有必要</li><li>另外，还有很多其他的限制</li></ul><p id="a5db"><em>选项2 —分割碎片— </em>使用碎片级别指标来仅分割已触发警报的碎片。一个简单的策略是按照散列范围对碎片进行排序，并首先分割最大的碎片。</p><h2 id="8eed">如何缩小Kinesis流</h2><p id="4156">要缩小<em> Kinesis </em>流，只需<a href="http://docs.aws.amazon.com/kinesis/latest/APIReference/API_MergeShards.html" target="_blank" rel="noreferrer noopener">合并</a>两个相邻的碎片。正如分割一个碎片会留下一个不活动的碎片，合并碎片会留下两个不活动的碎片。</p><p id="42ac">由于缩减规模主要是为了节约成本，我<strong>强烈建议</strong>不要过于频繁地缩减规模。相反，如果你在缩小规模后很快又不得不扩大规模，你很容易就会增加成本——从而留下许多不活跃的碎片。</p><p id="116f">由于我们不想频繁地缩减规模，因此使用cron作业(即<em> CloudWatch事件</em>+<em>λ</em>)比使用<em> CloudWatch警报</em>更有意义。经过反复试验，我们决定每36小时缩减一次，这是我们24小时保留策略的1.5倍。</p><h2 id="9cde">如何确定缩小哪个Kinesis流</h2><p id="5d80">当cron作业运行时，我们的<em> Lambda </em>函数将遍历所有的Kinesis流，对于每个流，我们将:</p><ul><li>根据每秒字节数和每秒记录数计算其调配的吞吐量</li><li>获取过去24小时内的5分钟指标(<code>IncomingBytes</code>和<code>IncomingRecords</code>)</li><li>如果过去24小时内的所有数据点都低于调配吞吐量的50%，则缩减数据流</li></ul><p id="a21f">我们采用5分钟指标的原因是因为这是<em> Kinesis </em>仪表板使用的粒度，允许我验证我的计算。请记住，您不会直接从<em> CloudWatch </em>获得<code>bytes/s</code>和<code>records/s</code>值，而是需要自己计算它们。</p><p id="0d66">此外，我们要求过去24小时内的所有数据点低于50%阈值。这有助于我们绝对确定利用率水平始终低于阈值，而不是可能由停机导致的暂时现象。</p><p id="6649">当考虑缩小Kinesis流的方法时，你会有与扩大相同的权衡——在使用<a href="http://docs.aws.amazon.com/kinesis/latest/APIReference/API_UpdateShardCount.html" target="_blank" rel="noreferrer noopener"> UpdateShardCount </a>和自己使用<a href="http://docs.aws.amazon.com/kinesis/latest/APIReference/API_MergeShards.html" target="_blank" rel="noreferrer noopener"> MergeShards </a>之间。</p><h3 id="ae97">包扎</h3><p id="4c45">为了设置一个流的初始<em> CloudWatch警报</em>，我们使用了一个repo来托管我们所有<em> Kinesis </em>流的配置。repo包含一个脚本，用于使用<em> CloudFormation </em>模板创建任何丢失的流和相关的<em> CloudWatch警报</em>。</p><figure class="wp-block-image size-large"><img loading="lazy" src="../Images/78bc76ca8accb994aba4cefafd70919f.png" alt="" class="wp-image-41783" data-original-src="https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/1_l1MbA3K-WxESv2fqG2FQeQ.png"/></figure><ul><li>每个环境都有一个配置文件，详细说明需要创建的所有Kinesis流，以及每个环境的最小和最大碎片数。</li><li>还有一个create-streams.js脚本，可以运行该脚本来创建环境中任何缺少的流，并具有所需的碎片数量。</li><li>该脚本还将使用CloudFormation模板创建相关的CloudWatch警报。</li><li>配置文件还指定了每个<em> Kinesis </em>流的最小和最大碎片数。当create-streams脚本创建一个新的流时，它将使用指定的<code>desiredShards</code>数量的碎片来创建。</li></ul><p id="e965">我希望你喜欢这篇文章——如果你正在做类似于自动缩放你的<em> Kinesis </em>流的事情，请分享你的经验，并在评论中告诉我！</p><h3 id="h-want-more-aws-goodness-check-these-out">想要更多AWS good？看看这些:</h3><p/></div></div>    
</body>
</html>
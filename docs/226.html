<html>
<head>
<title>Change Data Capture with Azure, PostgreSQL, and Kafka | A Cloud Guru</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>使用Azure、PostgreSQL和Kafka |云专家改变数据捕获</h1>
<blockquote>原文：<a href="https://acloudguru.com/blog/engineering/use-kafka-connect-to-build-a-data-pipeline-from-postgresql-to-azure-data-explorer#0001-01-01">https://acloudguru.com/blog/engineering/use-kafka-connect-to-build-a-data-pipeline-from-postgresql-to-azure-data-explorer#0001-01-01</a></blockquote><div><div class="elementor-widget-container"><p>这篇博文展示了如何使用变更数据捕获，通过使用<a href="https://kafka.apache.org/" target="_blank" rel="noreferrer noopener"> Apache Kafka </a>，将数据库修改从PostgreSQL流式传输到<a href="https://docs.microsoft.com/en-us/azure/data-explorer/" target="_blank" rel="noreferrer noopener"> Azure Data Explorer </a> (Kusto)。</p><p>变更数据捕获(CDC)用于跟踪数据库表中响应创建、更新和删除操作的行级更改。这是一种强大的技术，但是只有当有办法利用这些事件并使它们对其他服务可用时才有用。</p><p class="has-text-align-center"><em>想了解更多关于Azure认证的信息吗？</em> <br/> <em>查看我们的<a href="https://acloudguru.com/azure-cloud-training" target="_blank" rel="noreferrer noopener"> Azure认证和学习路径。</a> </em></p><h4 id="h-introduction">介绍</h4><p>使用Apache Kafka，可以将传统的批处理ETL过程转换为实时的流模式。你可以<a href="https://en.wikipedia.org/wiki/Do_it_yourself" target="_blank" rel="noreferrer noopener">自己动手</a>使用你选择的客户端SDK编写优秀的老Kafka生产者/消费者应用。但是，当有Kafka Connect及其即用型连接器套件时，您为什么要这样做呢？</p><p>一旦你选择了Kafka Connect，有几个选项。一个是JDBC源连接器，它主要通过轮询目标数据库表来提取信息。基于变更数据捕获，有一种更好的(尽管有点复杂)方法！进入<a href="https://debezium.io/" target="_blank" rel="noreferrer noopener"> Debezium </a>，这是一个分布式平台，构建在不同数据库中可用的变更数据捕获特性之上。它提供了一组<a href="https://debezium.io/documentation/reference/1.2/connectors/index.html" target="_blank" rel="noreferrer noopener"> Kafka Connect连接器</a>，这些连接器接入数据库表中的行级更改，并将它们转换成发送给Apache Kafka的事件流。一旦变更日志事件在Kafka中，它们将对所有下游应用程序可用。</p><p>与这篇博文相关的代码和配置可以在这个<a href="https://github.com/abhirockzz/kafka-adx-postgres-cdc-demo" target="_blank" rel="noreferrer noopener"> GitHub资源库</a>中找到</p><p>这是这篇文章中呈现的用例的高级概述。</p><p>与订单相关的数据存储在PostgreSQL数据库中，包含订单ID、客户ID、城市、交易金额等信息。时间等。这些数据被PostgreSQL的Debezium连接器拾取并发送给Kafka主题。一旦数据在Kafka中，另一个(sink)连接器将它们发送到Azure Data Explorer，允许进一步的查询和分析。</p><figure class="wp-block-image size-large"><img loading="lazy" src="../Images/a9d3f59649634e9b04464d56363dc0ca.png" alt="" class="wp-image-41298" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_1082/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.18.58-PM.png 1082w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_300/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.18.58-PM.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_1024/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.18.58-PM.png 1024w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_768/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.18.58-PM.png 768w" sizes="(max-width: 1082px) 100vw, 1082px" data-original-src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.18.58-PM.png"/></figure><p>端到端解决方案中使用的各个组件如下:</p><p>数据管道可能相当复杂！这篇博文提供了一个简单的例子，其中PostgreSQL数据库将被用作数据源，大数据分析引擎充当最终目的地(接收器)。这两个组件都运行在Azure中:<a href="https://acloudguru.com/course/using-microsoft-azure-database-services">Azure Database</a>for PostgreSQL(<a href="https://docs.microsoft.com/en-us/azure/postgresql/?WT.mc_id=acloudguru-blog-abhishgu"><em>Source</em></a>)是一个基于开源<a href="https://www.postgresql.org/"> Postgres </a>数据库引擎的关系数据库服务，而<a href="https://docs.microsoft.com/azure/data-explorer/?WT.mc_id=acloudguru-blog-abhishgu">Azure Data Explorer</a>(<em>Sink</em>)是一个快速且可扩展的数据探索服务，它允许您收集、存储和分析来自任何不同来源的大量数据，如网站、应用程序、物联网设备等。</p><p>虽然本博客中使用了Azure PostgreSQL数据库，但这些说明应该适用于任何Postgres数据库。如果你愿意，请随意使用其他选项！</p><p>Apache Kafka和Kafka Connect一起充当流数据管道的可扩展平台——这里的关键组件是源和接收器连接器。</p><p>用于PostgreSQL的Debezium连接器捕获插入、更新和删除数据库内容的行级更改，并提交给PostgreSQL数据库，生成数据更改事件记录，并将它们传输到Kafka主题。在幕后，它使用Postgres输出插件的组合(例如wal2json、pgoutput等。)并且(Java)连接器本身使用<a href="https://www.postgresql.org/docs/current/static/logicaldecoding-walsender.html" target="_blank" rel="noreferrer noopener"> PostgreSQL的流复制协议</a>和<a href="https://github.com/pgjdbc/pgjdbc" target="_blank" rel="noreferrer noopener"> JDBC驱动程序</a>读取由输出插件产生的变化。</p><p><a href="https://github.com/Azure/kafka-sink-azure-kusto" target="_blank" rel="noreferrer noopener"> Azure Data Explorer接收器连接器</a>从配置的Kafka主题中提取数据，批处理并将其发送到Azure Data Explorer，在Azure Data Explorer中它们被排队接收并最终写入Azure Data Explorer中的表。连接器利用了用于Azure Data Explorer的<a href="https://github.com/Azure/azure-kusto-java" target="_blank" rel="noreferrer noopener">Java SDK</a>。</p><p>大多数组件(除了Azure Data Explorer和Azure PostgreSQL DB)都作为Docker容器(使用Docker Compose)运行——Kafka(和Zookeeper)、Kafka Connect workers和数据生成器应用程序。话虽如此，只要所有组件都配置为根据需要相互访问和通信，这些指令将适用于任何Kafka集群和Kafka Connect workers。例如，你可以在Azure HD Insight上拥有Kafka集群，在Azure Marketplace上拥有T2融合云。</p><p>如果您对这些场景感兴趣，您可以查看这些<a href="https://github.com/Azure/azure-kusto-labs/tree/master/kafka-integration" target="_blank" rel="noreferrer noopener">动手实验</a>。</p><p>下面是组件及其服务定义的分类——你可以参考GitHub repo 中完整的docker-compose文件<a href="https://github.com/abhirockzz/kafka-adx-postgres-cdc-demo/blob/master/docker-compose.yaml" target="_blank" rel="noreferrer noopener">。</a></p><pre class="wp-block-preformatted">  zookeeper:<br/>    image: debezium/zookeeper:1.2<br/>    ports:<br/>      - 2181:2181<br/>  kafka:<br/>    image: debezium/kafka:1.2<br/>    ports:<br/>      - 9092:9092<br/>    links:<br/>      - zookeeper<br/>    depends_on:<br/>      - zookeeper<br/>    environment:<br/>      - ZOOKEEPER_CONNECT=zookeeper:2181<br/>      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092</pre><p>Kafka和Zookeeper使用<a href="https://hub.docker.com/r/debezium/kafka/"> debezium </a>图像运行——它们工作正常，非常适合快速反馈循环、演示等迭代开发。</p><pre class="wp-block-preformatted">dataexplorer-connector:<br/>    build:<br/>      context: ./connector<br/>      args:<br/>        KUSTO_KAFKA_SINK_VERSION: 1.0.1<br/>    ports:<br/>      - 8080:8083<br/>    links:<br/>      - kafka<br/>    depends_on:<br/>      - kafka<br/>    environment:<br/>      - BOOTSTRAP_SERVERS=kafka:9092<br/>      - GROUP_ID=adx<br/>      - CONFIG_STORAGE_TOPIC=adx_connect_configs<br/>      - OFFSET_STORAGE_TOPIC=adx_connect_offsets<br/>      - STATUS_STORAGE_TOPIC=adx_connect_statuses<br/>  postgres-connector:<br/>    image: debezium/connect:1.2<br/>    ports:<br/>      - 9090:8083<br/>    links:<br/>      - kafka<br/>    depends_on:<br/>      - kafka<br/>    environment:<br/>      - BOOTSTRAP_SERVERS=kafka:9092<br/>      - GROUP_ID=pg<br/>      - CONFIG_STORAGE_TOPIC=pg_connect_configs<br/>      - OFFSET_STORAGE_TOPIC=pg_connect_offsets<br/>      - STATUS_STORAGE_TOPIC=pg_connect_statuses</pre><p>Kafka Connect源和接收器连接器作为单独的容器运行，只是为了让您更容易理解和推理它们——也可以在单个容器中运行这两个连接器。</p><p>注意，虽然PostgreSQL连接器内置在<a href="https://hub.docker.com/r/debezium/connect"> debezium/connect </a>映像中，但是Azure Data Explorer连接器是使用自定义映像设置的。<a href="https://github.com/abhirockzz/kafka-adx-postgres-cdc-demo/blob/master/connector/Dockerfile">号Dockerfile </a>相当紧凑:</p><pre class="wp-block-preformatted">FROM debezium/connect:1.2<br/>WORKDIR $KAFKA_HOME/connect<br/>ARG KUSTO_KAFKA_SINK_VERSION<br/>RUN curl -L -O https://github.com/Azure/kafka-sink-azure-kusto/releases/download/v$KUSTO_KAFKA_SINK_VERSION/kafka-sink-azure-kusto-$KUSTO_KAFKA_SINK_VERSION-jar-with-dependencies.jar</pre><p>最后，orders-gen服务只是通过<a href="https://golang.org/"> Go </a>应用程序将随机订单数据植入PostgreSQL。可以参考<a href="https://github.com/abhirockzz/kafka-adx-postgres-cdc-demo/blob/master/orders-generator/Dockerfile">GitHub repo</a>中的Dockerfile</p><pre class="wp-block-preformatted">  orders-gen:<br/>    build:<br/>      context: ./orders-generator<br/>    environment:<br/>      - PG_HOST=&lt;postgres host&gt;<br/>      - PG_USER=&lt;postgres username&gt;<br/>      - PG_PASSWORD=&lt;postgres password&gt;<br/>      - PG_DB=&lt;postgres db name&gt;</pre><p>希望到现在为止，您已经对架构和相关组件有了合理的理解。在深入实际问题之前，你需要注意几件事情。</p><p>最后，克隆这个GitHub repo:</p><pre class="wp-block-preformatted">git clone https://github.com/abhirockzz/kafka-adx-postgres-cdc-demo<br/>cd kafka-adx-postgres-cdc-demo</pre><p>首先，让我们确保您已经设置并配置了Azure Data Explorer和PostgreSQL数据库。</p><p><strong> 1。创建一个Azure Data Explorer集群和一个数据库— <a href="https://docs.microsoft.com/azure/data-explorer/create-cluster-database-portal?WT.mc_id=acloudguru-blog-abhishgu" target="_blank" rel="noreferrer noopener">这个快速入门</a>将指导你完成这个过程。</strong></p><p><strong> 2。使用下面的<a href="https://docs.microsoft.com/azure/data-explorer/kql-quick-reference?WT.mc_id=acloudguru-blog-abhishgu" target="_blank" rel="noreferrer noopener"> KQL </a>查询创建一个表(Orders)和映射(OrdersEventMapping)</strong></p><pre class="wp-block-preformatted">.create table Orders (orderid: string, custid: string, city: string, amount: int, purchase_time: datetime)<br/><br/>.create table Orders ingestion json mapping 'OrdersEventMapping' '[{"column":"orderid","Properties":{"path":"$.orderid"}},{"column":"custid","Properties":{"path":"$.custid"}},{"column":"city","Properties":{"path":"$.city"}},{"column":"amount","Properties":{"path":"$.amount"}},{"column":"purchase_time","Properties":{"path":"$.purchase_time"}}]'</pre><p>在摄取过程中，Azure Data Explorer试图通过在小的入口数据块等待摄取时将它们批处理在一起来优化吞吐量，可以使用<a href="https://docs.microsoft.com/azure/data-explorer/kusto/management/batchingpolicy?WT.mc_id=acloudguru-blog-abhishgu" target="_blank" rel="noreferrer noopener">摄取批处理策略</a>来微调这一过程。或者，出于本演示的目的，您可以按如下方式更新策略:</p><pre class="wp-block-preformatted">.alter table Orders policy ingestionbatching @'{"MaximumBatchingTimeSpan":"00:00:30", "MaximumNumberOfItems": 500, "MaximumRawDataSizeMB": 1024}'<br/><br/>.show table &lt;enter database name&gt;.Orders policy ingestionbatching</pre><p><em>详见</em> <a href="https://docs.microsoft.com/azure/data-explorer/kusto/management/batching-policy?WT.mc_id=acloudguru-blog-abhishgu" target="_blank" rel="noreferrer noopener"> <em>摄取批处理策略命令参考</em> </a> <em/></p><p><strong> 3。为连接器创建服务主体，以进行身份验证并连接到Azure Data Explorer服务</strong>。如果你想使用Azure门户来做这件事，请参考<a href="https://docs.microsoft.com/azure/active-directory/develop/howto-create-service-principal-portal?WT.mc_id=acloudguru-blog-abhishgu" target="_blank" rel="noreferrer noopener"> How to:使用门户创建一个Azure广告应用和服务主体，可以访问资源</a>。以下示例使用了Azure CLI<a href="https://docs.microsoft.com/cli/azure/ad/sp?view=azure-cli-latest&amp;WT.mc_id=acloudguru-blog-abhishgu#az_ad_sp_create_for_rbac" target="_blank" rel="noreferrer noopener">az ad sp create-for-RBAC</a>命令。例如，要创建名为adx-sp的服务主体:</p><pre class="wp-block-preformatted">az ad sp create-for-rbac -n "adx-sp"</pre><p>您将得到一个JSON响应:</p><pre class="wp-block-preformatted">{<br/>  "appId": "fe7280c7-5705-4789-b17f-71a472340429",<br/>  "displayName": "kusto-sp",<br/>  "name": "http://kusto-sp",<br/>  "password": "29c719dd-f2b3-46de-b71c-4004fb6116ee",<br/>  "tenant": "42f988bf-86f1-42af-91ab-2d7cd011db42"<br/>}</pre><p>请记下appId、密码和租户，因为您将在后续步骤中使用它们。</p><p><strong> 4。向您的数据库添加权限</strong></p><p>为您刚刚创建的服务主体提供适当的角色。要分配管理员角色，<a href="https://docs.microsoft.com/azure/data-explorer/manage-database-permissions?WT.mc_id=acloudguru-blog-abhishgu#manage-permissions-in-the-azure-portal">按照本指南</a>使用Azure门户或在您的数据浏览器集群中使用以下命令</p><p>。添加数据库<enter database="" name="">管理员(' aad app =<enter service="" principal="" appid="">；<enter service="" principal="" tenant="">’)‘AAD App’</enter></enter></enter></p><p>你可以使用各种选项在Azure上设置PostgreSQL，包括<a href="https://docs.microsoft.com/azure/postgresql/quickstart-create-server-database-portal?WT.mc_id=acloudguru-blog-abhishgu" target="_blank" rel="noreferrer noopener"> Azure门户</a>、<a href="https://docs.microsoft.com/azure/postgresql/quickstart-create-server-database-azure-cli?WT.mc_id=acloudguru-blog-abhishgu" target="_blank" rel="noreferrer noopener"> Azure CLI </a>、<a href="https://docs.microsoft.com/azure/postgresql/quickstart-create-postgresql-server-database-using-azure-powershell?WT.mc_id=acloudguru-blog-abhishgu" target="_blank" rel="noreferrer noopener"> Azure PowerShell </a>和<a href="https://docs.microsoft.com/azure/postgresql/quickstart-create-postgresql-server-database-using-arm-template?tabs=azure-portal&amp;WT.mc_id=acloudguru-blog-abhishgu" target="_blank" rel="noreferrer noopener"> ARM模板</a>。一旦你这样做了，你就可以使用你最喜欢的编程语言，比如<a href="https://docs.microsoft.com/azure/postgresql/connect-java?WT.mc_id=acloudguru-blog-abhishgu" target="_blank" rel="noreferrer noopener"> Java </a>，<a href="https://docs.microsoft.com/azure/postgresql/connect-csharp?WT.mc_id=acloudguru-blog-abhishgu" target="_blank" rel="noreferrer noopener">轻松地连接到数据库。NET </a>、<a href="https://docs.microsoft.com/azure/postgresql/connect-nodejs?WT.mc_id=acloudguru-blog-abhishgu" target="_blank" rel="noreferrer noopener"> Node.js </a>、<a href="https://docs.microsoft.com/azure/postgresql/connect-python?WT.mc_id=acloudguru-blog-abhishgu" target="_blank" rel="noreferrer noopener"> Python </a>、<a href="https://docs.microsoft.com/azure/postgresql/connect-go?WT.mc_id=acloudguru-blog-abhishgu" target="_blank" rel="noreferrer noopener"> Go </a>等。</p><p><em>尽管上述参考资料针对单服务器部署模式，但请注意，</em> <a href="https://docs.microsoft.com/azure/postgresql/overview?WT.mc_id=acloudguru-blog-abhishgu#azure-database-for-postgresql---hyperscale-citus" target="_blank" rel="noreferrer noopener"> <em>超大规模(Citus)是另一种部署模式，您可以使用</em> </a> <em>来处理“接近或已经超过100 GB数据的工作负载”</em></p><p>请确保准备好以下PostgreSQL相关信息，因为您将需要它们来配置后续部分中的Debezium连接器——数据库主机名(和端口)、用户名、密码</p><p>为了让端到端解决方案按预期工作，我们需要:</p><ul><li>确保可以从本地Kafka Connect workers(容器)访问Azure中的PostgreSQL实例</li><li>确保适当的PostrgeSQL复制设置(“逻辑”)</li><li>创建Orders表，您将使用该表来测试变更数据捕获功能</li></ul><p>如果您使用Azure DB for PostgreSQL，使用<a href="https://docs.microsoft.com/azure/postgresql/howto-manage-firewall-using-cli?WT.mc_id=acloudguru-blog-abhishgu#create-firewall-rule" target="_blank" rel="noreferrer noopener">az postgres server firewall-rule create</a>命令创建一个防火墙规则，将您的主机列入白名单。由于我们在Docker中本地运行Kafka Connect，只需导航到Azure门户(我的PostrgreSQL实例的<strong>连接安全</strong>部分)并选择<strong>添加当前客户端IP地址</strong>以确保您的本地IP被添加到防火墙规则中:</p><figure class="wp-block-image size-large"><img loading="lazy" src="../Images/18f679f4efd80a70987ab5543a4f673f.png" alt="" class="wp-image-41306" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_1007/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.30.14-PM.png 1007w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_300/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.30.14-PM.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_768/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.30.14-PM.png 768w" sizes="(max-width: 1007px) 100vw, 1007px" data-original-src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.30.14-PM.png"/></figure><p>要更改Azure DB for PostgreSQL的复制模式，可以使用<a href="https://docs.microsoft.com/cli/azure/postgres/server/configuration?view=azure-cli-latest&amp;WT.mc_id=acloudguru-blog-abhishgu#az-postgres-server-configuration-set"> az postgres服务器配置</a>命令:</p><pre class="wp-block-preformatted">az postgres server configuration set --resource-group &lt;name of resource group&gt; --server-name &lt;name of server&gt; --name azure.replication_support --value logical</pre><p>..或者使用Azure门户中PostgreSQL实例的<strong>复制</strong>菜单:</p><figure class="wp-block-image size-large"><img loading="lazy" src="../Images/288566433192ab3d19fedd12dbe247f1.png" alt="" class="wp-image-41309" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_938/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.32.04-PM.png 938w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_300/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.32.04-PM.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_768/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.32.04-PM.png 768w" sizes="(max-width: 938px) 100vw, 938px" data-original-src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.32.04-PM.png"/></figure><p>更新配置后，您需要使用CLI(<a href="https://docs.microsoft.com/cli/azure/postgres/server?view=azure-cli-latest&amp;WT.mc_id=acloudguru-blog-abhishgu#az-postgres-server-restart" target="_blank" rel="noreferrer noopener">az postgres server restart</a>)或门户重新启动服务器。</p><p>一旦数据库启动并运行，就创建表。我在这个例子中使用了psql CLI，但是也可以随意使用其他工具。例如，通过SSL连接到Azure上的PostgreSQL数据库(系统会提示您输入密码):</p><pre class="wp-block-preformatted">psql -h &lt;POSTGRESQL_INSTANCE_NAME&gt;.postgres.database.azure.com -p 5432 -U &lt;POSTGRES_USER_NAME&gt; -W -d &lt;POSTGRES_DB_NAME&gt; --set=sslmode=require<br/><br/>//example<br/>psql -h my-pgsql.postgres.database.azure.com -p 5432 -U foo@my-pgsql -W -d postgres --set=sslmode=require</pre><p>使用下面的SQL创建表:</p><pre class="wp-block-preformatted">CREATE SCHEMA retail;<br/><br/>CREATE TABLE retail.orders_info (<br/>    orderid SERIAL NOT NULL PRIMARY KEY,<br/>    custid INTEGER NOT NULL,<br/>    amount INTEGER NOT NULL,<br/>    city VARCHAR(255) NOT NULL,<br/>    purchase_time VARCHAR(20) NOT NULL<br/>);</pre><p>purchase_time捕获执行购买的时间，但是它使用VARCHAR而不是TIMESTAMP类型(理想情况下)来降低整体复杂性。这是因为<a href="https://debezium.io/documentation/reference/1.2/connectors/postgresql.html#postgresql-timestamp-type" target="_blank" rel="noreferrer noopener"> Debezium Postgres连接器处理时间戳数据类型</a>的方式(这是正确的！)</p><p>在接下来的几节中，您将设置源(PostgreSQL)、接收器(Azure Data Explorer)连接器，并验证端到端管道。</p><p>多亏了Docker Compose，启动我们的本地环境非常容易。我们只需要一个命令:</p><pre class="wp-block-preformatted">docker-compose --project-name adx-kafka-cdc up --build</pre><p>这将与Kafka、Zookeeper和Kafka Connect workers一起构建(并启动)订单生成器应用程序容器。</p><p>下载和启动容器可能需要一段时间:这只是一次性的过程。</p><p>要确认是否所有容器都已启动:</p><pre class="wp-block-preformatted">docker-compose -p adx-kafka-cdc ps
</pre><p>订单生成器应用程序将开始向PostgreSQL中的orders_info表插入随机订单事件。此时，您还可以进行快速的健全性检查，以确认订单信息是否被持久化——在下面的示例中，我使用了<a href="https://www.postgresql.org/docs/13/app-psql.html" target="_blank" rel="noreferrer noopener"> psql </a>:</p><pre class="wp-block-preformatted">psql -h &lt;POSTGRESQL_INSTANCE_NAME&gt;.postgres.database.azure.com -p 5432 -U &lt;POSTGRES_USER_NAME&gt; -W -d &lt;POSTGRES_DB_NAME&gt; --set=sslmode=require<br/><br/>select * from retail.orders_info order by orderid desc limit 5;</pre><p>这将为您提供最近的五个订单:</p><pre class="wp-block-preformatted"> orderid | custid | amount |   city    |    purchase_time   <br/>---------+--------+--------+-----------+---------------------<br/>      10 |     77 |    140 | Seattle   | 2020-10-09 07:10:49<br/>      9  |    541 |    186 | Cleveland | 2020-10-09 07:10:46<br/>      8  |    533 |    116 | Cleveland | 2020-10-09 07:10:42<br/>      7  |    225 |    147 | Chicago   | 2020-10-09 07:10:39<br/>      6  |    819 |    184 | Austin    | 2020-10-09 07:10:36<br/>(5 rows)</pre><p>为了将订单数据传输到Kafka，我们需要配置并启动Debezium PostgreSQL源连接器的一个实例。</p><p>将下面的JSON内容复制到一个文件中(可以命名为pg-source-config.json)。请确保使用与您的PostgreSQL实例对应的值更新以下属性:database.hostname、database.user、database.password。</p><pre class="wp-block-preformatted">{<br/>    "name": "pg-orders-source",<br/>    "config": {<br/>        "connector.class": "io.debezium.connector.postgresql.PostgresConnector",<br/>        "database.hostname": "&lt;enter database name&gt;.postgres.database.azure.com",<br/>        "database.port": "5432",<br/>        "database.user": "&lt;enter admin username&gt;@&lt;enter database name&gt;",<br/>        "database.password": "&lt;enter admin password&gt;",<br/>        "database.dbname": "postgres",<br/>        "database.server.name": "myserver",<br/>        "plugin.name": "wal2json",<br/>        "table.whitelist": "retail.orders_info",<br/>        "value.converter": "org.apache.kafka.connect.json.JsonConverter"<br/>    }<br/>}</pre><p>在编写时，Debezium支持以下插件:decoderbufs、wal2json、wal2json_rds、wal2json_streaming、wal2json_rds_streaming和pgoutput。我在这个例子中使用了wal2json，Azure也支持它<a href="https://docs.microsoft.com/azure/postgresql/concepts-logical?WT.mc_id=acloudguru-blog-abhishgu"/>。</p><p>要启动连接器，只需使用<a href="https://acloudguru.com/hands-on-labs/consuming-kafka-messages-with-confluent-rest-proxy"> Kafka Connect REST代理</a>端点来提交配置。</p><pre class="wp-block-preformatted">curl -X POST -H "Content-Type: application/json" --data @pg-source-config.json http://localhost:9090/connectors<br/><br/># to confirm<br/>curl http://localhost:9090/connectors/pg-orders-source</pre><p><em>注意，REST端点的端口是9090。这是在docker-compose.yaml </em>中定义的每个服务端口映射</p><p>让我们来看看Kafka主题，看看由源连接器产生的变更数据捕获事件。</p><pre class="wp-block-preformatted">docker exec -it adx-kafka-cdc_kafka_1 bash</pre><p>你将被丢进一个壳里(在容器里)。执行以下命令以使用Kafka中的变更数据事件:</p><pre class="wp-block-preformatted">cd bin &amp;&amp; ./kafka-console-consumer.sh –topic myserver.retail.orders_info –bootstrap-server kafka:9092 –from-beginning</pre><p><em>注意，主题名</em><em>my server . retail . orders _ info</em><em>是Debezium连接器</em>使用的约定的结果</p><p>主题中的每个事件都对应一个特定的顺序。它是JSON格式的，如下图所示。请注意，有效负载还包含整个模式，为了简洁起见，该模式已被删除。</p><pre class="wp-block-preformatted">{<br/>    "schema": {....},<br/>    "payload": {<br/>        "before": null,<br/>        "after": {<br/>            "orderid": 51,<br/>            "custid": 306,<br/>            "amount": 183,<br/>            "city": "Austin",<br/>            "purchase_time":"2020-10-09 07:23:10"<br/>        },<br/>        "source": {<br/>            "version": "1.2.1.Final",<br/>            "connector": "postgresql",<br/>            "name": "myserver",<br/>            "ts_ms": 1602057392691,<br/>            "snapshot": "false",<br/>            "db": "postgres",<br/>            "schema": "retail",<br/>            "table": "orders_info",<br/>            "txId": 653,<br/>            "lsn": 34220200,<br/>            "xmin": null<br/>        },<br/>        "op": "c",<br/>        "ts_ms": 1602057392818,<br/>        "transaction": null<br/>    }<br/>}</pre><p>到目前为止，我们已经有了前半部分的管道。让我们开始第二部分吧！</p><p>将下面的JSON内容复制到一个文件中(可以将其命名为adx-sink-config.json)。根据您的Azure Data Explorer设置替换以下属性的值-aad . auth . authority、aad.auth.appid、aad.auth.appkey、kusto.tables.topics.mapping(数据库名称)和kusto.url</p><pre class="wp-block-preformatted">{<br/>    "name": "adx-orders-sink",<br/>    "config": {<br/>        "connector.class": "com.microsoft.azure.kusto.kafka.connect.sink.KustoSinkConnector",<br/>        "flush.size.bytes": 10000,<br/>        "flush.interval.ms": 30000,<br/>        "tasks.max": 2,<br/>        "topics": "myserver.retail.orders_info",<br/>        "kusto.tables.topics.mapping": "[{'topic': 'myserver.retail.orders_info','db': '&lt;enter database name&gt;', 'table': 'Orders','format': 'json', 'mapping':'OrdersEventMapping'}]",<br/>        "aad.auth.authority": "&lt;enter tenant ID from service principal info&gt;",<br/>        "kusto.url": "https://ingest-&lt;enter cluster name&gt;.&lt;enter region&gt;.kusto.windows.net",<br/>        "aad.auth.appid": "&lt;enter app ID from service principal info&gt;",<br/>        "aad.auth.appkey": "&lt;enter password from service principal info&gt;",<br/>        "key.converter": "org.apache.kafka.connect.storage.StringConverter",<br/>        "transforms": "unwrap",<br/>        "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState"<br/>    }<br/>}</pre><p>注意，这里使用了Kafka Connect <a href="https://kafka.apache.org/documentation/#connect_transforms">单消息转换</a>(SMT)——这是Debezium提供的ExtractNewRecordState转换。你可以在文档中详细阅读<a href="https://debezium.io/documentation/reference/1.2/configuration/event-flattening.html"/></p><pre class="wp-block-preformatted">"transforms": "unwrap",<br/>"transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState"</pre><p>它从JSON有效负载中删除了模式和其他部分，只保留所需的内容。在这种情况下，我们从after属性(在有效负载中)中寻找订单信息。例如</p><pre class="wp-block-preformatted">{<br/>    "orderid": 51,<br/>    "custid": 306,<br/>    "amount": 183,<br/>    "city": "Austin",<br/>    "purchase_time":"2020-10-09 07:23:10"<br/>}</pre><p>当然，您可以对此进行不同的建模(在源连接器本身中应用转换)，但是这种方法有几个好处:</p><ol type="1"><li>仅将相关数据发送到Azure Data Explorer</li><li>Kafka主题包含<em>整个</em>变更数据事件(以及模式),任何下游服务都可以利用该事件</li></ol><p>要安装连接器，只需像以前一样使用Kafka Connect REST端点:</p><pre class="wp-block-preformatted">curl -X POST -H "Content-Type: application/json" --data @adx-sink-config.json http://localhost:8080/connectors<br/><br/># check status<br/>curl http://localhost:8080/connectors/adx-orders-sink/status</pre><p><em>注意，REST端点的端口是8080。这是在docker-compose.yaml </em>中定义的每个服务端口映射</p><p>连接器应该投入运行，向Azure Data Explorer进行身份验证，并开始批处理接收过程。</p><p><em>注意，flush.size.bytes和flush.interval.ms用于调节批处理过程。请参考</em> <a href="https://github.com/Azure/kafka-sink-azure-kusto/blob/master/README.md#5-sink-properties" target="_blank" rel="noreferrer noopener"> <em>连接器文档</em> </a> <em>了解各个属性的详细信息。</em></p><p>由于连接器的刷新配置和Azure Data Explorer中Orders表的批处理策略相当激进(出于演示目的)，您应该会看到数据快速流入Data Explorer。</p><p>您可以在数据资源管理器中查询Orders表来分割数据。下面是一些简单的查询。</p><p>获取纽约市订单的详细信息:</p><pre class="wp-block-preformatted">Orders<br/>| where city == 'New York'</pre><figure class="wp-block-image size-large"><img loading="lazy" src="../Images/71f8508c53142cd357e626af95a3d2eb.png" alt="" class="wp-image-41313" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_956/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.37.28-PM.png 956w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_300/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.37.28-PM.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_768/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.37.28-PM.png 768w" sizes="(max-width: 956px) 100vw, 956px" data-original-src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.37.28-PM.png"/></figure><p>仅获取来自纽约市的订单的购买金额和时间，并按金额排序:</p><pre class="wp-block-preformatted">Orders<br/>| where city == 'New York'<br/>| project amount, purchase_time<br/>| sort by amount</pre><figure class="wp-block-image size-large"><img loading="lazy" src="../Images/bc5230ddbc39205b011dbcd582ca878c.png" alt="" class="wp-image-41315" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_795/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.37.59-PM.png 795w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_300/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.37.59-PM.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_768/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.37.59-PM.png 768w" sizes="(max-width: 795px) 100vw, 795px" data-original-src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.37.59-PM.png"/></figure><p>找出每个城市的平均销售额，并用柱形图表示出来:</p><pre class="wp-block-preformatted">Orders<br/>| summarize avg_sales = avg(amount) by city<br/>| render columnchart</pre><figure class="wp-block-image size-large"><img loading="lazy" src="../Images/57e282957fd428f7e7c7c1f0ededf86c.png" alt="" class="wp-image-41317" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_983/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.38.32-PM.png 983w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_300/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.38.32-PM.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_768/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.38.32-PM.png 768w" sizes="(max-width: 983px) 100vw, 983px" data-original-src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.38.32-PM.png"/></figure><p>每个城市的总购买量，以饼图表示:</p><pre class="wp-block-preformatted">Orders<br/>| summarize total = sum(amount) by city<br/>| sort by total<br/>| render piechart</pre><figure class="wp-block-image size-large"><img loading="lazy" src="../Images/dafee5d8c9a6bfddb146f824abcd8e34.png" alt="" class="wp-image-41318" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_1008/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.38.55-PM.png 1008w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_300/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.38.55-PM.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_768/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.38.55-PM.png 768w" sizes="(max-width: 1008px) 100vw, 1008px" data-original-src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.38.55-PM.png"/></figure><p>每个城市的订单数量，以折线图表示:</p><pre class="wp-block-preformatted">Orders<br/>| summarize orders = count() by city<br/>| sort by orders<br/>| render linechart  </pre><figure class="wp-block-image size-large"><img loading="lazy" src="../Images/fad4187608dcc3786cbed58c8c0b425b.png" alt="" class="wp-image-41319" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_1000/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.39.18-PM.png 1000w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_300/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.39.18-PM.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_768/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.39.18-PM.png 768w" sizes="(max-width: 1000px) 100vw, 1000px" data-original-src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.39.18-PM.png"/></figure><p>购买量在一天内如何变化？</p><pre class="wp-block-preformatted">Orders<br/>| extend hour = floor(purchase_time % 1d , 10m)<br/>| summarize event_count=count() by hour<br/>| sort by hour asc<br/>| render timechart</pre><figure class="wp-block-image size-large"><img loading="lazy" src="../Images/d83c7d7eb0c041594821b574068d826f.png" alt="" class="wp-image-41320" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_993/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.39.39-PM.png 993w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_300/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.39.39-PM.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_768/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.39.39-PM.png 768w" sizes="(max-width: 993px) 100vw, 993px" data-original-src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.39.39-PM.png"/></figure><p>在不同的城市，一天之内它是如何变化的？</p><pre class="wp-block-preformatted">Orders<br/>| extend hour= floor( purchase_time % 1d , 10m)<br/>| where city in ("New Delhi", "Seattle", "New York", "Austin", "Chicago", "Cleveland")<br/>| summarize event_count=count() by hour, city<br/>| render columnchart</pre><figure class="wp-block-image size-large"><img loading="lazy" src="../Images/a68f4a2bf4262876c75e014b55650340.png" alt="" class="wp-image-41322" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_1004/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.40.10-PM.png 1004w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_300/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.40.10-PM.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_768/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.40.10-PM.png 768w" sizes="(max-width: 1004px) 100vw, 1004px" data-original-src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.40.10-PM.png"/></figure><h3 id="h-azure-data-explorer-dashboards">Azure数据浏览器仪表板</h3><p>您可以组合一个或多个这样的查询，并创建实时仪表板。例如:</p><figure class="wp-block-image size-large"><img loading="lazy" src="../Images/35de881377db9b5a0f1c3cec5a3bcffb.png" alt="" class="wp-image-41323" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_1010/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.40.35-PM.png 1010w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_300/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.40.35-PM.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto,w_768/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.40.35-PM.png 768w" sizes="(max-width: 1010px) 100vw, 1010px" data-original-src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/10/Screen-Shot-2020-10-28-at-5.40.35-PM.png"/></figure><p>要了解更多信息，请查看如何<a href="https://docs.microsoft.com/en-us/azure/data-explorer/azure-data-explorer-dashboards" target="_blank" rel="noreferrer noopener">使用Azure Data Explorer仪表盘可视化数据</a></p><p>要停止容器，您可以:</p><pre class="wp-block-preformatted">docker-compose -p adx-kafka-cdc down -v</pre><p>要删除Azure Data Explorer集群/数据库，请使用<a href="https://docs.microsoft.com/cli/azure/kusto/cluster?view=azure-cli-latest&amp;WT.mc_id=acloudguru-blog-abhishgu#az-kusto-cluster-delete"> az集群删除</a>或<a href="https://docs.microsoft.com/cli/azure/kusto/database?view=azure-cli-latest&amp;WT.mc_id=acloudguru-blog-abhishgu#az-kusto-database-delete"> az kusto数据库删除</a>。对于PostgreSQL，只需使用<a href="https://docs.microsoft.com/cli/azure/postgres/server?view=azure-cli-latest&amp;WT.mc_id=acloudguru-blog-abhishgu#az_postgres_server_delete"> az postgres服务器删除</a></p><pre class="wp-block-preformatted">az postgres server delete -g &lt;resource group name&gt; -n &lt;server name&gt;<br/>az kusto cluster delete -n &lt;cluster name&gt; -g &lt;resource group name&gt;<br/>az kusto database delete -n &lt;database name&gt; --cluster-name &lt;cluster name&gt; -g &lt;resource group name&gt;</pre><h3 id="h-conclusion">结论</h3><p>Kafka Connect帮助您构建可扩展的数据管道，而无需编写定制的管道代码。您主要需要设置、配置，当然还有操作连接器。</p><p>请记住，Kafka Connect worker实例只是JVM进程，根据您的规模和需求，您可以选择使用Docker容器的形式来操作它们，使用一流的编排服务，如<a href="https://docs.microsoft.com/azure/aks/?WT.mc_id=acloudguru-blog-abhishgu" target="_blank" rel="noreferrer noopener"> Azure Kubernetes服务</a>。因为Kafka Connect实例是无状态的实体，所以您在集群工作负载的拓扑和规模方面有很大的自由度！</p><p>如果您想进一步探索，我建议您深入以下主题:</p><p class="has-text-align-center"><em>想了解更多关于Azure认证的信息吗？</em> <br/> <em>查看我们的<a href="https://acloudguru.com/azure-cloud-training" target="_blank" rel="noreferrer noopener"> Azure认证和学习路径。</a> </em></p><h3 id="h-about-the-author">关于作者</h3><p>Abhishek Gupta是微软的高级开发人员。你可以在<a href="https://twitter.com/abhi_tweeter" target="_blank" rel="noreferrer noopener"> Twitter </a>上关注他，在<a href="https://in.linkedin.com/in/abhirockzz" target="_blank" rel="noreferrer noopener"> LinkedIn </a>上联系他，或者关注他的<a href="https://medium.com/@abhishek1987" target="_blank" rel="noreferrer noopener">博客</a>。</p></div></div>    
</body>
</html>